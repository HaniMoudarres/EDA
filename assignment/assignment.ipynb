{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** To compute the sample mean of a variable $X$:\n",
    "$$\n",
    "m(X) = \\dfrac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n",
    "and sample covariance of two variables $X$ and $Y$,\n",
    "$$\n",
    "\\text{cov}(X,Y) = \\dfrac{1}{N} \\sum_{i=1}^N (x_i - m(X))(y_i - m(Y))).\n",
    "$$\n",
    "Recall, the sample variance of $X$ is\n",
    "$$\n",
    "s^2 = \\dfrac{1}{N} \\sum_{i=1}^N (x_i - m(X))^2.\n",
    "$$\n",
    "It can be very helpful to understand some basic properties of these statistics. If you want to write your calculations on a piece of paper, take a photo, and upload that to your GitHub repo, that's probably easiest.\n",
    "\n",
    "1. Show that $m(a + bX) = a+b \\times m(X)$.\n",
    "2. Show that $\\text{cov}(X,a+bY) = b \\times \\text{cov}(X,Y)$\n",
    "3. Show that $\\text{cov}(a+bX,a+bX) = b^2 \\text{cov}(X,X) $, and in particular that $\\text{cov}(X,X) = s^2 $.\n",
    "4. Instead of the mean, consider the median. Consider transformations that are non-decreasing (if $x\\ge x'$, then $g(x)\\ge g(x')$), like $2+5 \\times X$ or $\\text{arcsinh}(X)$. Is a non-decreasing transformation of the median the median of the transformed variable? Explain. Does your answer apply to any quantile? The IQR? The range? \n",
    "5. Consider a non-decreasing transformation $g()$. Is is always true that $m(g(X))= g(m(X))$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pictures of solutions attached as \"Q1_Page_1.jpg\" and \"Q1_Page_2.jpg\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** This question looks at financial transfers from foreign entities to American universities. In particular, from which countries and giftors are the gifts coming from, and to which institutions are they going? For this question, `.groupby([vars]).count()` and `.groupby([vars]).sum()` will be especially useful to tally the number of occurrences and sum the values of those occurrences.\n",
    "\n",
    "1. Load the `./data/ForeignGifts_edu.csv` dataset.\n",
    "2. For `Foreign Gift Amount`, create a histogram and describe the variable. Describe your findings.\n",
    "<br><br>\n",
    "The average (mean) foreign gift amount is approximately $588,232. However, the standard deviation is very large (~$3.2 million), indicating high variability.\n",
    "<br><br>\n",
    "3. For `Gift Type`, create a histogram or value counts table. What proportion of the gifts are contracts, real estate, and monetary gifts?\n",
    "<br><br>\n",
    "~61.2% (17,274) are contracts, ~38.8% (10,936) are monetary gifts, ~0.04% (11) are real estate.\n",
    "<br><br>\n",
    "4. Create a kernel density plot of the log of `Foreign Gift Amount`, and then a kernel density plot of the log of `Foreign Gift Amount` conditional on gift type. Do you notice any patterns?\n",
    "<br><br>\n",
    "When separated by Gift Type, you can see distinct patterns. Contracts and Monetary Gifts have overlapping but slightly different peaks. Real Estate has an especially distinct peak.\n",
    "<br><br>\n",
    "5. What are the top 15 countries in terms of the number of gifts? What are the top 15 countries in terms of the amount given?\n",
    "<br><br>\n",
    "Top 15 by Amount:<br>\n",
    " Country of Giftor<br>\n",
    "QATAR                   <br>\n",
    "ENGLAND                 <br>\n",
    "CHINA                   <br>\n",
    "SAUDI ARABIA            <br>\n",
    "BERMUDA                  <br>\n",
    "CANADA                   <br>\n",
    "HONG KONG                <br>\n",
    "JAPAN                    <br>\n",
    "SWITZERLAND              <br>\n",
    "INDIA                    <br>\n",
    "GERMANY                  <br>\n",
    "UNITED ARAB EMIRATES     <br>\n",
    "FRANCE                   <br>\n",
    "SINGAPORE                <br>\n",
    "AUSTRALIA                \n",
    "<br><br>\n",
    "6. What are the top 15 institutions in terms of the total amount of money they receive? Make a histogram of the total amount received by all institutions. \n",
    "<br><br>\n",
    "Top 15 Institutions by Amount:\n",
    "Institution Name:\n",
    "Carnegie Mellon University                    <br>\n",
    "Cornell University                               <br>\n",
    "Harvard University                                <br>\n",
    "Massachusetts Institute of Technology             <br>\n",
    "Yale University                                   <br>\n",
    "Texas A&M University                              <br>\n",
    "Johns Hopkins University                          <br>\n",
    "Northwestern University                           <br>\n",
    "Georgetown University                             <br>\n",
    "University of Chicago (The)                       <br>\n",
    "University of Colorado Boulder                    <br>\n",
    "Duke University                                   <br>\n",
    "Brigham Young University                          <br>\n",
    "Stanford University                               <br>\n",
    "University of Texas MD Anderson Cancer Center    \n",
    "<br><br>\n",
    "7. Which giftors provide the most money, in total?\n",
    "<br><br>\n",
    "The giftor providing the most money is the Qatar Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the dataset\n",
    "filename = '/Users/hanimoudarres/Downloads/Foundations of ML/EDA/assignment/data/ForeignGifts_edu.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# --- Q2.2 Foreign Gift Amount ---\n",
    "print(\"\\n--- Q2.2 Foreign Gift Amount ---\")\n",
    "# Describe the variable\n",
    "print(df['Foreign Gift Amount'].describe())\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Using a log scale for the y-axis to better visualize the wide range of frequencies\n",
    "plt.hist(df['Foreign Gift Amount'], bins=50, edgecolor='black')\n",
    "plt.title('Histogram of Foreign Gift Amount')\n",
    "plt.xlabel('Amount ($)')\n",
    "plt.ylabel('Frequency (Log Scale)')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# --- Q2.3 Gift Type ---\n",
    "print(\"\\n--- Q2.3 Gift Type ---\")\n",
    "# Value counts and proportions\n",
    "gift_counts = df['Gift Type'].value_counts()\n",
    "gift_proportions = df['Gift Type'].value_counts(normalize=True)\n",
    "print(\"Counts:\\n\", gift_counts)\n",
    "print(\"Proportions:\\n\", gift_proportions)\n",
    "\n",
    "# --- Q2.4 Kernel Density Plots ---\n",
    "# Create log of Foreign Gift Amount\n",
    "# We use numpy's log function. Note: This assumes amounts are positive. \n",
    "# The description showed a negative min, but for log plots we typically filter or handle <= 0.\n",
    "# Here we filter for positive amounts for the log plot.\n",
    "df_pos = df[df['Foreign Gift Amount'] > 0].copy()\n",
    "df_pos['Log Foreign Gift Amount'] = np.log(df_pos['Foreign Gift Amount'])\n",
    "\n",
    "# KDE of Log Amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(df_pos['Log Foreign Gift Amount'], fill=True)\n",
    "plt.title('KDE of Log Foreign Gift Amount')\n",
    "plt.xlabel('Log(Amount)')\n",
    "plt.show()\n",
    "\n",
    "# KDE Conditional on Gift Type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df_pos, x='Log Foreign Gift Amount', hue='Gift Type', common_norm=False)\n",
    "plt.title('KDE of Log Foreign Gift Amount by Gift Type')\n",
    "plt.show()\n",
    "\n",
    "# --- Q2.5 Top 15 Countries ---\n",
    "print(\"\\n--- Q2.5 Top 15 Countries ---\")\n",
    "# Top 15 by number of gifts\n",
    "top_countries_count = df['Country of Giftor'].value_counts().head(15)\n",
    "print(\"Top 15 by Count:\\n\", top_countries_count)\n",
    "\n",
    "# Top 15 by amount given\n",
    "top_countries_amt = df.groupby('Country of Giftor')['Foreign Gift Amount'].sum().sort_values(ascending=False).head(15)\n",
    "print(\"Top 15 by Amount:\\n\", top_countries_amt)\n",
    "\n",
    "# --- Q2.6 Top 15 Institutions & Histogram ---\n",
    "print(\"\\n--- Q2.6 Top 15 Institutions ---\")\n",
    "# Total amount per institution\n",
    "inst_totals = df.groupby('Institution Name')['Foreign Gift Amount'].sum()\n",
    "top_inst = inst_totals.sort_values(ascending=False).head(15)\n",
    "print(\"Top 15 Institutions by Amount:\\n\", top_inst)\n",
    "\n",
    "# Histogram of total amounts received by all institutions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(inst_totals, bins=50, edgecolor='black')\n",
    "plt.title('Histogram of Total Amounts Received by Institutions')\n",
    "plt.xlabel('Total Amount Received ($)')\n",
    "plt.ylabel('Number of Institutions')\n",
    "plt.yscale('log') # Log scale for readability\n",
    "plt.show()\n",
    "\n",
    "# --- Q2.7 Top Giftors ---\n",
    "print(\"\\n--- Q2.7 Top Giftors ---\")\n",
    "top_giftors = df.groupby('Giftor Name')['Foreign Gift Amount'].sum().sort_values(ascending=False).head(15)\n",
    "print(\"Top Giftors by Amount:\\n\", top_giftors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** This question uses the Airbnb data to practice making visualizations.\n",
    "\n",
    "  1. Load the `./data/airbnb_hw.csv` data with Pandas. This provides a dataset of AirBnB rental properties for New York City.  \n",
    "  2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
    "  <br><br>\n",
    "  The dataset consists of 30,478 observations across 13 distinct variables. The variables included in the dataset are Host Id, Host Since, Name, Neighbourhood, Property Type, Review Scores Rating (bin), Room Type, Zipcode, Beds, Number of Records, Number Of Reviews, Price, and Review Scores Rating.\n",
    "  <br><br>\n",
    "  3. Cross tabulate `Room Type` and `Property Type`. What patterns do you see in what kinds of rentals are available? For which kinds of properties are private rooms more common than renting the entire property?\n",
    "  <br><br>\n",
    "  When crossing the room type and property type, we see a heavy concentration of standard apartments which are mostly rented out as entire homes. Private rooms are significantly more common than renting out the entire property when looking at houses, bed and breakfasts, and dorms, likely because hosts live in these structures and simply rent out their spare spaces to guests.\n",
    "  <br><br>\n",
    "  4. For `Price`, make a histogram, kernel density, box plot, and a statistical description of the variable. Are the data badly scaled? Are there many outliers? Use `log` to transform price into a new variable, `price_log`, and take these steps again.\n",
    "  <br><br>\n",
    "  The initial statistical description and graphs for price show that the data is very badly scaled and extremely right-skewed. There are many massive outliers stretching up to ten thousand dollars which causes the vast majority of standard listings to be visually crushed into a single thin sliver on the graphs. After transforming the price using a natural log, the data becomes beautifully normalized, resulting in a classic bell-shaped curve for the histogram and kernel density plots that makes the core distribution easily readable.\n",
    "  <br><br>\n",
    "  5. Make a scatterplot of `price_log` and `Beds`. Describe what you see. Use `.groupby()` to compute a desciption of `Price` conditional on/grouped by the number of beds. Describe any patterns you see in the average price and standard deviation in prices.\n",
    "  <br><br>\n",
    "  The scatterplot of the log price against the number of beds displays a broad positive correlation where the price generally increases alongside the bed count. Grouping the data by beds reveals that the average price climbs consistently as properties get larger, and it also shows that the standard deviation in price dramatically increases as the number of beds grows, indicating that the market for large multi-bed listings is far more volatile and variable.\n",
    "  <br><br>\n",
    "  6. Make a scatterplot of `price_log` and `Beds`, but color the graph by `Room Type` and `Property Type`. What patterns do you see? Compute a description of `Price` conditional on `Room Type` and `Property Type`. Which Room Type and Property Type have the highest prices on average? Which have the highest standard deviation? Does the mean or median appear to be a more reliable estimate of central tendency, and explain why?\n",
    "  <br><br>\n",
    "  Coloring the scatterplot reveals distinct vertical stratification where entire homes or apartments consistently command higher log prices than private or shared rooms regardless of the bed count. Based on the statistical description, entire home and apartment listings categorized under the \"Other\" property type have the absolute highest average price, and this specific subset also exhibits the highest standard deviation in the dataset. Because of the massive price outliers that artificially stretch out these averages, the median is a much more reliable estimate of central tendency as it resists skewing and accurately reflects what a standard guest is likely to pay.\n",
    "  <br><br>\n",
    "  7. We've looked a bit at this `price_log` and `Beds` scatterplot. Use seaborn to make a `jointplot` with `kind=hex`. Where are the data actually distributed? How does it affect the way you think about the plots in 5 and 6?\n",
    "  <br><br>\n",
    "  The hex jointplot reveals that the overwhelming bulk of the data is densely concentrated in the bottom left portion of the graph, corresponding to one or two beds at affordable price points. This radically changes the way we should interpret the earlier scatterplots, because standard scatter points completely overlap one another and create a visual illusion that huge or ultra-expensive properties are common, while the hex plot correctly proves they are actually extreme rarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Load the dataset\n",
    "# Cleaning the Price column during load as it contains commas and is interpreted as strings\n",
    "df = pd.read_csv('/Users/hanimoudarres/Downloads/Foundations of ML/EDA/assignment/data/airbnb_hw.csv')\n",
    "df['Price'] = df['Price'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# 2. Dimensions, observations, variables, and head\n",
    "print(\"Dimensions:\", df.shape)\n",
    "print(\"Variables:\", df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "# 3. Cross tabulate Room Type and Property Type\n",
    "print(pd.crosstab(df['Room Type'], df['Property Type']))\n",
    "\n",
    "# 4. Price visualizations and description\n",
    "print(df['Price'].describe())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['Price'].dropna(), bins=50, edgecolor='black')\n",
    "plt.title(\"Histogram of Price\")\n",
    "plt.xlabel(\"Price ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(df['Price'].dropna(), fill=True)\n",
    "plt.title(\"Kernel Density of Price\")\n",
    "plt.xlabel(\"Price ($)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=df['Price'].dropna())\n",
    "plt.title(\"Box Plot of Price\")\n",
    "plt.xlabel(\"Price ($)\")\n",
    "plt.show()\n",
    "\n",
    "# Log transform (replacing 0 with NaN to avoid log(0) errors)\n",
    "df['price_log'] = np.log(df['Price'].replace(0, np.nan))\n",
    "print(df['price_log'].describe())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['price_log'].dropna(), bins=50, edgecolor='black')\n",
    "plt.title(\"Histogram of Log Price\")\n",
    "plt.xlabel(\"Log Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(df['price_log'].dropna(), fill=True)\n",
    "plt.title(\"Kernel Density of Log Price\")\n",
    "plt.xlabel(\"Log Price\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=df['price_log'].dropna())\n",
    "plt.title(\"Box Plot of Log Price\")\n",
    "plt.xlabel(\"Log Price\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Scatterplot and groupby beds\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(df['Beds'], df['price_log'], alpha=0.5)\n",
    "plt.title(\"Scatterplot of Log Price vs Beds\")\n",
    "plt.xlabel(\"Beds\")\n",
    "plt.ylabel(\"Log Price\")\n",
    "plt.show()\n",
    "\n",
    "print(df.groupby('Beds')['Price'].describe())\n",
    "\n",
    "# 6. Scatterplot colored by room type and property type\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='Beds', y='price_log', hue='Room Type', style='Property Type', alpha=0.7)\n",
    "plt.title(\"Log Price vs Beds by Room & Property Type\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(df.groupby(['Room Type', 'Property Type'])['Price'].describe())\n",
    "\n",
    "# 7. Jointplot with hex\n",
    "sns.jointplot(data=df, x='Beds', y='price_log', kind='hex', gridsize=20, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** This question looks at a time series of the number of active oil drilling rigs in the United States over time. The data comes from the Energy Information Agency.\n",
    "\n",
    "1. Load `./data/drilling_rigs.csv` and examine the data. How many observations? How many variables? Are numeric variables correctly read in by Pandas, or will some variables have to be typecast/coerced? Explain clearly how these data need to be cleaned.\n",
    "<br><br>\n",
    "The dataset contains exactly 623 observations across 10 total variables. Many of the numeric variables are not correctly read in by Pandas initially, because the dataset uses the specific text string \"Not Available\" to represent missing information, which forces Pandas to interpret those columns as generic text objects rather than numbers. To properly clean this data, you must replace the \"Not Available\" strings with genuine null values such as numpy's NaN, and then explicitly coerce those affected columns into floating-point numerical types using a function like pd.to_numeric() so they can be accurately plotted and manipulated.\n",
    "<br><br>\n",
    "2. To convert the `Month` variable to an ordered datetime variable, use `df['time'] = pd.to_datetime(df['Month'], format='mixed')`.\n",
    "<br><br>\n",
    "3. Let's look at `Active Well Service Rig Count (Number of Rigs)`, which is the total number of rigs over time. Make a line plot of this time series. Describe what you see.\n",
    "<br><br>\n",
    "Plotting the total number of active rigs over time reveals a massive historical peak in the early 1980s where the active rig count surged well past five thousand before rapidly crashing shortly after. Following this immense peak, the active rig count experiences a general downward trend over the ensuing decades with several smaller cyclical peaks and troughs. The total count eventually hits a historic minimum down near 450 active rigs around the year 2020, likely tied to pandemic-related market shocks, before showing a slight recovery in more recent years.\n",
    "<br><br>\n",
    "4. Instead of levels, we want to look at change over time. Compute the first difference of  `Active Well Service Rig Count (Number of Rigs)` and plot it over time. Describe what you see.\n",
    "<br><br>\n",
    "The first difference plot represents the month-to-month change in the number of active rigs, and it clearly demonstrates that the series was incredibly volatile during its peak in the 1980s. During this chaotic time, the number of active rigs swung wildly with single-month growth jumps of over six hundred rigs and sudden crashes exceeding a thousand rigs. In contrast, the period from the late 1990s onward exhibits much lower variance and tighter, smaller fluctuations, showing a much more stabilized overall market outside of isolated historical events.\n",
    "<br><br>\n",
    "5. The first two columns are the number of onshore and offshore rigs, respectively. Melt these columns and plot the resulting series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Q4.1 Load the drilling_rigs.csv data\n",
    "filepath = '/Users/hanimoudarres/Downloads/Foundations of ML/EDA/assignment/data/drilling_rigs.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# Examine the data\n",
    "print(\"Dimensions:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nData Types Before Cleaning:\\n\", df.dtypes)\n",
    "print(df.head())\n",
    "\n",
    "# Clean the data by replacing 'Not Available' with NaN and coercing to numeric\n",
    "df = df.replace('Not Available', np.nan)\n",
    "for col in df.columns:\n",
    "    if col != 'Month':\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nData Types After Cleaning:\\n\", df.dtypes)\n",
    "\n",
    "# Q4.2 Convert Month variable to ordered datetime\n",
    "df['time'] = pd.to_datetime(df['Month'], format='mixed')\n",
    "df = df.sort_values('time')\n",
    "\n",
    "# Q4.3 Line plot of Active Well Service Rig Count\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['time'], df['Active Well Service Rig Count (Number of Rigs)'])\n",
    "plt.title('Active Well Service Rig Count Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Active Rigs')\n",
    "plt.show()\n",
    "\n",
    "# Q4.4 Compute first difference and plot\n",
    "df['rig_count_diff'] = df['Active Well Service Rig Count (Number of Rigs)'].diff()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['time'], df['rig_count_diff'])\n",
    "plt.title('First Difference of Active Well Service Rig Count')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Month-over-Month Change in Rigs')\n",
    "plt.show()\n",
    "\n",
    "# Q4.5 Melt first two columns (Onshore and Offshore) and plot\n",
    "# Identifying the specific names for the onshore and offshore columns\n",
    "onshore_col = 'Crude Oil and Natural Gas Rotary Rigs in Operation, Onshore (Number of Rigs)'\n",
    "offshore_col = 'Crude Oil and Natural Gas Rotary Rigs in Operation, Offshore (Number of Rigs)'\n",
    "\n",
    "df_melted = df.melt(\n",
    "    id_vars=['time'], \n",
    "    value_vars=[onshore_col, offshore_col],\n",
    "    var_name='Rig Location', \n",
    "    value_name='Count'\n",
    ")\n",
    "\n",
    "# Renaming the values for a much cleaner legend\n",
    "df_melted['Rig Location'] = df_melted['Rig Location'].map({\n",
    "    onshore_col: 'Onshore Rigs',\n",
    "    offshore_col: 'Offshore Rigs'\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_melted, x='time', y='Count', hue='Rig Location')\n",
    "plt.title('Onshore vs. Offshore Rigs Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Rigs')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
